{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4fccaaa-fda5-4f99-a4c5-c463c5c890f5",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_video_transcript_translate_with_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4540e-4987-4774-9305-764c3133e953",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "# Auto Generated Agent Chat: Translating Video audio using Whisper and GPT-3.5-turbo\n",
    "In this notebook, we demonstrate how to use whisper and GPT-3.5-turbo with `AssistantAgent` and `UserProxyAgent` to recognize and translate\n",
    "the speech sound from a video file and add the timestamp like a subtitle file based on [agentchat_function_call.ipynb](https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd644cc-2b14-4700-8b1d-959fb2e9acb0",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install `openai`, `pyautogen`, `whisper`, and `moviepy`:\n",
    "```bash\n",
    "pip install openai\n",
    "pip install openai-whisper\n",
    "pip install moviepy\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4600b8-c6df-49dd-945d-ce69f30a65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install moviepy~=1.0.3\n",
    "# %pip install openai-whisper~=20230918\n",
    "# %pip install openai~=1.3.5\n",
    "# %pip install \"pyautogen>=0.2.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bdeb0b-c4b6-4dec-97d2-d84f09cffa00",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "It is recommended to store your OpenAI API key in the environment variable. For example, store it in `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d1ae87-f007-4286-a56a-dcf68abf9393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"model\": \"gpt-4-1106-preview\", \"api_key\": \"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\"}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser, JsonKeyOutputFunctionsParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager, ConversableAgent\n",
    "\n",
    "from autogen.cache import Cache\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4-1106-preview',\n",
    "        'api_key': os.getenv(\"OPENAI_API_KEY\"),\n",
    "    },\n",
    "]\n",
    "\n",
    "print(json.dumps(config_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a17e36-fde4-434c-825c-d00034f7f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated by datamodel-codegen:\n",
    "#   filename:  schema_v3.json\n",
    "#   timestamp: 2024-01-15T16:43:18+00:00\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from enum import Enum\n",
    "from typing import Optional, List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class ContactType(Enum):\n",
    "    Phone = 'Phone'\n",
    "    Text = 'Text'\n",
    "\n",
    "\n",
    "class CustomerNeed(Enum):\n",
    "    Complete_purchase_support = 'Complete purchase support'\n",
    "    Technical_support = 'Technical support'\n",
    "    Membership_management = 'Membership management'\n",
    "    Other = 'Other'\n",
    "\n",
    "\n",
    "class EmployeeResponse(Enum):\n",
    "    Added_protection_plan_to_product = 'Added protection plan to product'\n",
    "    Engaged_manager_or_support = 'Engaged manager or support'\n",
    "    Fixed_in_the_moment = 'Fixed in the moment'\n",
    "    Gave_recommendation_or_advice = 'Gave recommendation or advice'\n",
    "    Started_remote_support_session = 'Started remote support session'\n",
    "    Unable_to_resolve_to_satisfaction = 'Unable to resolve to satisfaction'\n",
    "    Canceled_membership = 'Canceled membership'\n",
    "    Explained_membership_benefits = 'Explained membership benefits'\n",
    "    Referred_to_other_team___unable_to_help = 'Referred to other team - unable to help'\n",
    "    Renewed_membership = 'Renewed membership'\n",
    "    Other = 'Other'\n",
    "\n",
    "\n",
    "class CustomerSentimentGoingIn(Enum):\n",
    "    Positive = 'Positive'\n",
    "    Negative = 'Negative'\n",
    "    Neutral = 'Neutral'\n",
    "\n",
    "\n",
    "class CustomerSentimentGoingOut(Enum):\n",
    "    Positive = 'Positive'\n",
    "    Negative = 'Negative'\n",
    "    Neutral = 'Neutral'\n",
    "\n",
    "class GiftCard(BaseModel):\n",
    "    giftCardOffered: bool = Field(..., title=\"Was a gift card offered to the customer?\")\n",
    "    giftCardAmount: str = Field(..., title=\"Dollar amount of the gift card offered\")\n",
    "    giftCardAccepted: bool = Field(..., title=\"If gift card was offered, did the customer accept the gift card?\")\n",
    "\n",
    "\n",
    "class CaseSchema(BaseModel):\n",
    "    \"\"\" Information about the Customer's Case Conversation \"\"\"\n",
    "    summary: str = Field(..., title='A detailed summary of the entire call transcript. Be sure to include why the customer was calling and if the customers issue was resolved, please provide those details in your summary. Do not use the customer or agents actual name in the summary, just refer to them as either \"Agent\" or \"Customer\"!')\n",
    "    orderNumber: str = Field(..., title=\"The customer's order number\")\n",
    "    productSKU: str = Field(..., title=\"The SKU associated to the product the customer might be calling about\")\n",
    "    driver: str = Field(..., title=\"A name or description that could be used to identify the individual delivering and/or doing service at the customer's house\")\n",
    "    photos: bool = Field(..., title=\"where photos captured at the customer's house showing damage or product condition?\")\n",
    "    agentCall: bool = Field(..., title=\"Did the agent or delivery person make a call while at the customer's house?\")                     \n",
    "    contactType: ContactType = Field(..., title='Contact Channel')\n",
    "    productSafteyFlag: bool = Field(..., title='Is there a product safety concern?')\n",
    "    customerNeed: CustomerNeed = Field(..., title='Customer Need')\n",
    "    employeeResponse: EmployeeResponse = Field(..., title='Employee Response')\n",
    "    customerSentimentGoingIn: CustomerSentimentGoingIn = Field(..., title=\"The customer's sentiment going into the conversation with agent\")\n",
    "    customerSentimentGoingOut: CustomerSentimentGoingOut = Field(..., title=\"The customer's sentiment at the end of the conversation with agent\")\n",
    "    giftCards: GiftCard = Field(..., title=\"Were gift cards offered and if so, were they accepted by the customer?\")\n",
    "    agentName: Optional[str] = Field(None, title='The name of the agent')\n",
    "    customerName: Optional[str] = Field(None, title='The name of the customer')\n",
    "    required: List[str] = Field(..., title=\"List of elements that are required to be present in the extracted entities output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324fec65-ab23-45db-a7a8-0aaf753fe19c",
   "metadata": {},
   "source": [
    "## Example and Output\n",
    "Below is an example of speech recognition from a [Peppa Pig cartoon video clip](https://drive.google.com/file/d/1QY0naa2acHw2FuH7sY3c-g2sBLtC2Sv4/view?usp=drive_link) originally in English and translated into Chinese.\n",
    "'FFmpeg' does not support online files. To run the code on the example video, you need to download the example video locally. You can change `your_file_path` to your local video file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed549b75-b4ea-4ec5-8c0b-a15e93ffd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json1 = {\n",
    "  \"transcript\": [{\n",
    "    \"source\": \"agent\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:17.671956\",\n",
    "    \"message\": \"Hi Thanks for calling geek squad. My name is Valerie before we start. May I please have your full name and your phone number.\"\n",
    "  }, {\n",
    "    \"source\": \"customer\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:27.609811\",\n",
    "    \"message\": \"No. Yes, I just I'm sorry I think I was in the wrong department I need to talk to somebody about printer I recently bought, order number 12345.\"\n",
    "  }, {\n",
    "    \"source\": \"agent\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:33.117753\",\n",
    "    \"message\": \"Uh Yes, I am from computing services, but what do you need? I'm sorry I cannot hear you properly.\"\n",
    "  }, {\n",
    "    \"source\": \"customer\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:37.875478\",\n",
    "    \"message\": \"I need to know if you sell a specific type of printer in.\"\n",
    "  }, {\n",
    "    \"source\": \"agent\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:41.890700\",\n",
    "    \"message\": \"Okay, I am going to provide you the phone number of the right department. Okay?\"\n",
    "  }, {\n",
    "    \"source\": \"customer\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:48.074268\",\n",
    "    \"message\": \"No cause I already called and was on hold for 12 minutes and I got disconnected. So can you connect me.\"\n",
    "  }, {\n",
    "    \"source\": \"agent\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:52.816488\",\n",
    "    \"message\": \"Uh, yes, for sure. Thank you so much for calling geek squad and have a wonderful day.\"\n",
    "  }, {\n",
    "    \"source\": \"customer\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:54.107702\",\n",
    "    \"message\": \"Thank you.\"\n",
    "  }, {\n",
    "    \"source\": \"agent\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:52.816488\",\n",
    "    \"message\": \"For your trouble, I would like to offer you a $20 gift card, would that be acceptable?\"\n",
    "  }, {\n",
    "    \"source\": \"customer\",\n",
    "    \"timestamp\": \"2024-01-17T18:26:54.107702\",\n",
    "    \"message\": \"No, that is ok..\"\n",
    "  }, {\n",
    "    \"source\": \"agent\",\n",
    "    \"timestamp\": \"2024-01-17T18:27:39.057198\",\n",
    "    \"message\": \"All agents are busy at this time. Please hold.\"\n",
    "  }, {\n",
    "    \"source\": \"system\",\n",
    "    \"message\": \"Based on this call, the following elements are required:  ['orderNumber', 'productSKU']\"\n",
    "  }]\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class ExecutorGroupchat(GroupChat):\n",
    "    dedicated_executor: UserProxyAgent = None\n",
    "\n",
    "    def select_speaker(\n",
    "        self, last_speaker: ConversableAgent, selector: ConversableAgent\n",
    "    ):\n",
    "        \"\"\"Select the next speaker.\"\"\"\n",
    "\n",
    "        try:\n",
    "            message = self.messages[-1]\n",
    "            if \"function_call\" in message:\n",
    "                return self.dedicated_executor\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "        selector.update_system_message(self.select_speaker_msg())\n",
    "        final, name = selector.generate_oai_reply(\n",
    "            self.messages\n",
    "            + [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"Read the above conversation. Then select the next role from {self.agent_names} to play. Only return the role.\",\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        if not final:\n",
    "            # i = self._random.randint(0, len(self._agent_names) - 1)  # randomly pick an id\n",
    "            return self.next_agent(last_speaker)\n",
    "        try:\n",
    "            return self.agent_by_name(name)\n",
    "        except ValueError:\n",
    "            return self.next_agent(last_speaker)\n",
    "\n",
    "# json_buffer = io.StringIO()\n",
    "\n",
    "# # Use json.dump() to encode the dictionary to a JSON string\n",
    "# json.dump(input_json, json_buffer)\n",
    "\n",
    "# # Get the JSON string from the buffer\n",
    "# json_string = json_buffer.getvalue()\n",
    "\n",
    "\n",
    "# @user_proxy.register_for_execution()\n",
    "# @chatbot.register_for_llm(description=\"Call transcript entity extractor.\")\n",
    "def extract_entities(call_transcript_id: Annotated[str, \"The id of the call transcript to be processed\"], ) -> str:\n",
    "    try:\n",
    "        print(f\"Transcript ID: {call_transcript_id}\")\n",
    "        # model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\")\n",
    "        model = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\")\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\",\n",
    "             \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "\n",
    "        case_extraction_functions = [convert_pydantic_to_openai_function(CaseSchema)]\n",
    "        extraction_model = model.bind(\n",
    "            functions=case_extraction_functions,\n",
    "            function_call={\"name\": \"CaseSchema\"}\n",
    "        )\n",
    "        extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()\n",
    "        # Run\n",
    "        json_output = extraction_chain.invoke({\"input\": call_transcript_sample})\n",
    "        # return json_output\n",
    "        return json.dumps(json_output)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {str(e)}\"\n",
    "\n",
    "\n",
    "# @user_proxy.register_for_execution()\n",
    "# @chatbot.register_for_llm(description=\"Format json to look pretty\")\n",
    "def style_output(input_json: Annotated[str, \"The JSON string to be formatted\"], ) -> str:\n",
    "    try:\n",
    "        print(f\"input_json: {input_json}\")\n",
    "        # Print output\n",
    "        # json_dict = json.loads(input_json)\n",
    "        # json_pretty = json.dumps(json_dict, indent=4)\n",
    "        json_pretty = json.dumps(input_json, indent=4)\n",
    "        print(json_pretty)\n",
    "        return json_pretty\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {str(e)}\"\n",
    "\n",
    "\n",
    "def find_missing_values(extract_entities_output: Annotated[str, \"The JSON object to look in for missing values\"], ) -> \\\n",
    "        List[str]:\n",
    "    result_list = []\n",
    "\n",
    "    try:\n",
    "        # Parse the JSON data\n",
    "        data = json.loads(extract_entities_output)\n",
    "\n",
    "        # Check if \"required\" key is present in the JSON\n",
    "        if \"required\" in data:\n",
    "            required_keys = data[\"required\"]\n",
    "\n",
    "            # Loop through the elements in the \"required\" array\n",
    "            for element in required_keys:\n",
    "                # Check if the element is a key in the JSON\n",
    "                if element in data:\n",
    "                    # Check if the value for the key is either null or empty\n",
    "                    if data[element] is None or (isinstance(data[element], str) and not data[element].strip()):\n",
    "                        result_list.append(missing_value_dict[element])\n",
    "                else:\n",
    "                    result_list.append(missing_value_dict[element])\n",
    "        else:\n",
    "            print('\"required\" key not found in the JSON data.')\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f'Error decoding JSON: {e}')\n",
    "\n",
    "    return result_list\n",
    "\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": 42,\n",
    "    \"temperature\": 0,\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"description\": \"Function to be called when text needs to be extracted from Call Transcripts.\",\n",
    "            \"name\": \"extract_entities\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"call_transcript_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The id of the call transcript to be processed\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"call_transcript_id\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"description\": \"Function to be called to determine if there are missing values from the response returned by the extract_entities function. If there are missing values, then that list should be sent to the user_proxy for follow up with the human.\",\n",
    "            \"name\": \"find_missing_values\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"extract_entities_output\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The JSON output from the extract_entities function\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"extract_entities_output\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"description\": \"Function to be called when content needs to be formatted to look nice.\",\n",
    "            \"name\": \"style_output\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"input_json\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The JSON string to be formatted\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"input_json\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "llm_config_short = {\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": 42,\n",
    "    \"temperature\": 0\n",
    "}\n",
    "\n",
    "software_engineer_agent_prompt = '''\n",
    "    You are a helpful assistant that is proficient at using python to parse json and look for missing keys and values.\n",
    "    Once you have completed assisting the user output TERMINATE\n",
    "    '''\n",
    "\n",
    "software_engineer_agent = AssistantAgent(\n",
    "    name=\"software_engineer_agent\",\n",
    "    system_message=software_engineer_agent_prompt,\n",
    "    llm_config=llm_config,\n",
    "    description=\"\"\"\n",
    "    This agent is responsible for parsing the output from the text_extractor_agent and making sure that all the required keys and values\n",
    "    are there. \n",
    "    If there are missing values, then that list of missing values must be sent to user_proxy agent so that the user_proxy can follow up \n",
    "    with the human to get values for those required keys.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "text_extractor_agent_prompt = '''\n",
    "    This agent is a helpful assistant that can extract text from call transcripts. This agent is NOT responsible for finding missing\n",
    "    values in the call transcript or extracted entities JSON!\n",
    "    Once you have completed assisting the user output TERMINATE\n",
    "    '''\n",
    "\n",
    "text_extractor_agent = AssistantAgent(\n",
    "    name=\"text_extractor_agent\",\n",
    "    system_message=text_extractor_agent_prompt,\n",
    "    llm_config=llm_config,\n",
    "    description='''\n",
    "     This agent should not be participating in the task of finding missing values!\n",
    "     There are two scenarios where the this agent will extract entities from the provided call transcript:\n",
    "     1.) When the chat manager is initially sent a request by the user_agent. This is always the first step to occur in the workflow.\n",
    "     2.) The other time is after the software_engineer_agent has performed its work and there are missing values identified, the human will provide\n",
    "     values for those missing values and after those are provided, this agent should once again extract the entities from the provided \n",
    "     call transcript, however, this time, the agent will replace the missing values with what the human provided.\n",
    "     If you ever get confused as to whether or not you should update a value, don't ask the user for approval, just update the entity value that the Human user provided.\n",
    "    '''\n",
    ")\n",
    "\n",
    "styling_agent_prompt = '''\n",
    "    This agent is a helpful assistant that can format content to look very pleasing to the user.\n",
    "    Once you have completed assisting the user output TERMINATE\n",
    "    '''\n",
    "\n",
    "styling_agent = AssistantAgent(\n",
    "    name=\"styling_agent\",\n",
    "    system_message=styling_agent_prompt,\n",
    "    llm_config=llm_config,\n",
    "    description=\"\"\"\n",
    "        This agent is responsible for formatting the final output returned from this group chat. This agent will always be the last agent to run.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    system_message=\"A human that will provide the necessary information to the group chat manager. Execute suggested function calls.\",\n",
    "    function_map={\n",
    "        \"extract_entities\": extract_entities,\n",
    "        \"find_missing_values\": find_missing_values,\n",
    "        \"style_output\": style_output,\n",
    "    },\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    "    code_execution_config={\"last_n_messages\": 4, \"work_dir\": \"groupchat\"},\n",
    "    human_input_mode=\"ALWAYS\"\n",
    ")\n",
    "\n",
    "groupchat = ExecutorGroupchat( agents=[user_proxy, text_extractor_agent, software_engineer_agent, styling_agent ], messages=[],max_round=20, dedicated_executor = user_proxy)\n",
    "# groupchat = GroupChat(\n",
    "#     agents=[user_proxy, text_extractor_agent, software_engineer_agent, content_beautifier_agent, function_executor_agent ], messages=[],\n",
    "#     max_round=5)\n",
    "manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config_short)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a589ce-7c3b-4041-adbc-340fcb761384",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.llm_config[\"tools\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "625fd7a4-286b-4e48-8e47-db1d3edd906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "       For the call transcript with id 1, please extract all the entities in the corresponding call transcript and resolve any\n",
      "       missing values identified by conversing with the human.\n",
      "       \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mtext_extractor_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: extract_entities *****\u001b[0m\n",
      "Arguments: \n",
      "{\"call_transcript_id\":\"1\"}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION extract_entities...\u001b[0m\n",
      "Transcript ID: 1\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"extract_entities\" *****\u001b[0m\n",
      "{\"summary\": \"Customer called to inquire about a specific type of printer and mentioned a recent purchase with order number 12345. The customer was initially in the wrong department and was seeking to be connected to the correct one. The agent offered a $20 gift card for the trouble, but the customer declined it.\", \"orderNumber\": \"12345\", \"productSKU\": \"\", \"driver\": \"\", \"photos\": false, \"agentCall\": true, \"contactType\": \"Phone\", \"productSafteyFlag\": false, \"customerNeed\": \"Technical support\", \"employeeResponse\": \"Referred to other team - unable to help\", \"customerSentimentGoingIn\": \"Neutral\", \"customerSentimentGoingOut\": \"Neutral\", \"giftCards\": {\"giftCardOffered\": true, \"giftCardAmount\": \"20\", \"giftCardAccepted\": false}, \"agentName\": \"Valerie\", \"customerName\": null, \"required\": [\"orderNumber\", \"productSKU\"]}\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msoftware_engineer_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: find_missing_values *****\u001b[0m\n",
      "Arguments: \n",
      "{\"extract_entities_output\":\"{\\\"summary\\\": \\\"Customer called to inquire about a specific type of printer and mentioned a recent purchase with order number 12345. The customer was initially in the wrong department and was seeking to be connected to the correct one. The agent offered a $20 gift card for the trouble, but the customer declined it.\\\", \\\"orderNumber\\\": \\\"12345\\\", \\\"productSKU\\\": \\\"\\\", \\\"driver\\\": \\\"\\\", \\\"photos\\\": false, \\\"agentCall\\\": true, \\\"contactType\\\": \\\"Phone\\\", \\\"productSafteyFlag\\\": false, \\\"customerNeed\\\": \\\"Technical support\\\", \\\"employeeResponse\\\": \\\"Referred to other team - unable to help\\\", \\\"customerSentimentGoingIn\\\": \\\"Neutral\\\", \\\"customerSentimentGoingOut\\\": \\\"Neutral\\\", \\\"giftCards\\\": {\\\"giftCardOffered\\\": true, \\\"giftCardAmount\\\": \\\"20\\\", \\\"giftCardAccepted\\\": false}, \\\"agentName\\\": \\\"Valerie\\\", \\\"customerName\\\": null, \\\"required\\\": [\\\"orderNumber\\\", \\\"productSKU\\\"]}\"}\n",
      "\u001b[32m********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION find_missing_values...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"find_missing_values\" *****\u001b[0m\n",
      "['productSKU']\n",
      "\u001b[32m****************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  productSKU value should be 1919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "productSKU value should be 1919\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mtext_extractor_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: pretty_print *****\u001b[0m\n",
      "Arguments: \n",
      "{\"input_json\":\"{\\\"summary\\\": \\\"Customer called to inquire about a specific type of printer and mentioned a recent purchase with order number 12345. The customer was initially in the wrong department and was seeking to be connected to the correct one. The agent offered a $20 gift card for the trouble, but the customer declined it.\\\", \\\"orderNumber\\\": \\\"12345\\\", \\\"productSKU\\\": \\\"1919\\\", \\\"driver\\\": \\\"\\\", \\\"photos\\\": false, \\\"agentCall\\\": true, \\\"contactType\\\": \\\"Phone\\\", \\\"productSafteyFlag\\\": false, \\\"customerNeed\\\": \\\"Technical support\\\", \\\"employeeResponse\\\": \\\"Referred to other team - unable to help\\\", \\\"customerSentimentGoingIn\\\": \\\"Neutral\\\", \\\"customerSentimentGoingOut\\\": \\\"Neutral\\\", \\\"giftCards\\\": {\\\"giftCardOffered\\\": true, \\\"giftCardAmount\\\": \\\"20\\\", \\\"giftCardAccepted\\\": false}, \\\"agentName\\\": \\\"Valerie\\\", \\\"customerName\\\": null}\"}\n",
      "\u001b[32m*************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION pretty_print...\u001b[0m\n",
      "input_json: {\"summary\": \"Customer called to inquire about a specific type of printer and mentioned a recent purchase with order number 12345. The customer was initially in the wrong department and was seeking to be connected to the correct one. The agent offered a $20 gift card for the trouble, but the customer declined it.\", \"orderNumber\": \"12345\", \"productSKU\": \"1919\", \"driver\": \"\", \"photos\": false, \"agentCall\": true, \"contactType\": \"Phone\", \"productSafteyFlag\": false, \"customerNeed\": \"Technical support\", \"employeeResponse\": \"Referred to other team - unable to help\", \"customerSentimentGoingIn\": \"Neutral\", \"customerSentimentGoingOut\": \"Neutral\", \"giftCards\": {\"giftCardOffered\": true, \"giftCardAmount\": \"20\", \"giftCardAccepted\": false}, \"agentName\": \"Valerie\", \"customerName\": null}\n",
      "\"{\\\"summary\\\": \\\"Customer called to inquire about a specific type of printer and mentioned a recent purchase with order number 12345. The customer was initially in the wrong department and was seeking to be connected to the correct one. The agent offered a $20 gift card for the trouble, but the customer declined it.\\\", \\\"orderNumber\\\": \\\"12345\\\", \\\"productSKU\\\": \\\"1919\\\", \\\"driver\\\": \\\"\\\", \\\"photos\\\": false, \\\"agentCall\\\": true, \\\"contactType\\\": \\\"Phone\\\", \\\"productSafteyFlag\\\": false, \\\"customerNeed\\\": \\\"Technical support\\\", \\\"employeeResponse\\\": \\\"Referred to other team - unable to help\\\", \\\"customerSentimentGoingIn\\\": \\\"Neutral\\\", \\\"customerSentimentGoingOut\\\": \\\"Neutral\\\", \\\"giftCards\\\": {\\\"giftCardOffered\\\": true, \\\"giftCardAmount\\\": \\\"20\\\", \\\"giftCardAccepted\\\": false}, \\\"agentName\\\": \\\"Valerie\\\", \\\"customerName\\\": null}\"\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"pretty_print\" *****\u001b[0m\n",
      "\"{\\\"summary\\\": \\\"Customer called to inquire about a specific type of printer and mentioned a recent purchase with order number 12345. The customer was initially in the wrong department and was seeking to be connected to the correct one. The agent offered a $20 gift card for the trouble, but the customer declined it.\\\", \\\"orderNumber\\\": \\\"12345\\\", \\\"productSKU\\\": \\\"1919\\\", \\\"driver\\\": \\\"\\\", \\\"photos\\\": false, \\\"agentCall\\\": true, \\\"contactType\\\": \\\"Phone\\\", \\\"productSafteyFlag\\\": false, \\\"customerNeed\\\": \\\"Technical support\\\", \\\"employeeResponse\\\": \\\"Referred to other team - unable to help\\\", \\\"customerSentimentGoingIn\\\": \\\"Neutral\\\", \\\"customerSentimentGoingOut\\\": \\\"Neutral\\\", \\\"giftCards\\\": {\\\"giftCardOffered\\\": true, \\\"giftCardAmount\\\": \\\"20\\\", \\\"giftCardAccepted\\\": false}, \\\"agentName\\\": \\\"Valerie\\\", \\\"customerName\\\": null}\"\n",
      "\u001b[32m*********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcontent_beautifier_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "The entities from the call transcript with id 1 have been successfully extracted and formatted. Here is the summary:\n",
      "\n",
      "- **Summary**: Customer called to inquire about a specific type of printer and mentioned a recent purchase with order number 12345. The customer was initially in the wrong department and was seeking to be connected to the correct one. The agent offered a $20 gift card for the trouble, but the customer declined it.\n",
      "- **Order Number**: 12345\n",
      "- **Product SKU**: 1919\n",
      "- **Driver**: (Not provided)\n",
      "- **Photos**: false\n",
      "- **Agent Call**: true\n",
      "- **Contact Type**: Phone\n",
      "- **Product Safety Flag**: false\n",
      "- **Customer Need**: Technical support\n",
      "- **Employee Response**: Referred to other team - unable to help\n",
      "- **Customer Sentiment Going In**: Neutral\n",
      "- **Customer Sentiment Going Out**: Neutral\n",
      "- **Gift Cards**:\n",
      "  - Gift Card Offered: true\n",
      "  - Gift Card Amount: $20\n",
      "  - Gift Card Accepted: false\n",
      "- **Agent Name**: Valerie\n",
      "- **Customer Name**: (Not provided)\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# user_proxy.initiate_chat(\n",
    "#     chatbot,\n",
    "#     message=\"For the call transcript with id 1, please extract all the entities in the corresponding call transcript\",\n",
    "#     llm_config=llm_config,\n",
    "# )\n",
    "\n",
    "#with Cache.disk():\n",
    "    # start the conversation\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"\n",
    "       For the call transcript with id 1, please extract all the entities in the corresponding call transcript and resolve any\n",
    "       missing values identified by conversing with the human.\n",
    "       \"\"\",\n",
    ")\n",
    "# print(user_proxy.chat_messages[text_extractor_agent])\n",
    "# print(user_proxy.chat_messages[software_engineer_agent])\n",
    "# print(user_proxy.chat_messages[manager])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
